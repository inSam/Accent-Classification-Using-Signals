{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(mfccs, labels, window_size=64, stride=32):\n",
    "    chunk = []\n",
    "    chunk_labels = []\n",
    "    for mfcc, label in zip(mfccs, labels):\n",
    "        # (W - F + 2P)/S + 1\n",
    "        for start in range(0, int((mfcc.shape[1] - window_size)/stride)+1): \n",
    "            chunk.append(mfcc[:, start * stride:(start * stride + window_size)])\n",
    "            chunk_labels.append(label)\n",
    "    return(chunk, chunk_labels)\n",
    "\n",
    "train_Y, test_Y = pickle.load(open('train_labels.dump', 'rb'))\n",
    "train_X = pickle.load(open('train_mfcc.dump', 'rb'))\n",
    "test_X = pickle.load(open('test_mfcc.dump', 'rb'))\n",
    "\n",
    "train_X, train_Y = make_chunks(train_X, train_Y)\n",
    "test_X, test_Y = make_chunks(test_X, test_Y)\n",
    "train_X = np.array(train_X)\n",
    "test_X =  np.array(test_X)\n",
    "train_Y = np.array(train_Y)\n",
    "test_Y = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X.reshape([train_X.shape[0], -1]))\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(train_X.reshape([train_X.shape[0], -1]), train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(test_X.reshape([test_X.shape[0], -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4215841343229103"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.equal(y_pred, test_Y)) / len(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 13, 64])\n",
      "tensor([5, 5, 0, 0, 0, 2, 1, 6, 5, 6, 0, 0, 6, 3, 2, 0, 3, 1, 0, 0, 7, 0, 1, 0,\n",
      "        0, 1, 2, 0, 0, 3, 3, 0])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.label = torch.from_numpy(label).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index:int):\n",
    "        x = self.data[index]\n",
    "        y = self.label[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x[np.newaxis, ...], y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = MyDataset(train_X, train_Y)\n",
    "loader =  DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "idx, (data, label) = next(enumerate(loader))\n",
    "print(data.shape)\n",
    "print(label)\n",
    "#for batch_idx, (data, target) in enumerate(loader):\n",
    "    #print('Batch idx {}, data shape {}, target shape {}'.format(batch_idx, data.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "#resnet18 = models.resnet18()\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, bias=False),\n",
    "    torch.nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=(1,2)),\n",
    "    \n",
    "    torch.nn.Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1,1), bias=False),\n",
    "    torch.nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1,1), bias=False),\n",
    "    torch.nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    \n",
    "    torch.nn.Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1,1), bias=False),\n",
    "    torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1,1), bias=False),\n",
    "    torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "#    torch.nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(\n",
    "        in_features=2304,\n",
    "        out_features=128\n",
    "    ),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(\n",
    "        in_features=128,\n",
    "        out_features=8\n",
    "    )\n",
    ")\n",
    "#print(model(data).shape)\n",
    "#print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1013] loss: 0.809\n",
      "[2,  1013] loss: 0.726\n",
      "[3,  1013] loss: 0.660\n",
      "[4,  1013] loss: 0.598\n",
      "[5,  1013] loss: 0.538\n",
      "[6,  1013] loss: 0.482\n",
      "[7,  1013] loss: 0.423\n",
      "[8,  1013] loss: 0.370\n",
      "[9,  1013] loss: 0.315\n",
      "[10,  1013] loss: 0.269\n",
      "[11,  1013] loss: 0.224\n",
      "[12,  1013] loss: 0.191\n",
      "[13,  1013] loss: 0.157\n",
      "[14,  1013] loss: 0.137\n",
      "[15,  1013] loss: 0.122\n",
      "[16,  1013] loss: 0.104\n",
      "[17,  1013] loss: 0.094\n",
      "[18,  1013] loss: 0.086\n",
      "[19,  1013] loss: 0.079\n",
      "[20,  1013] loss: 0.073\n",
      "[21,  1013] loss: 0.066\n",
      "[22,  1013] loss: 0.069\n",
      "[23,  1013] loss: 0.060\n",
      "[24,  1013] loss: 0.058\n",
      "[25,  1013] loss: 0.059\n",
      "[26,  1013] loss: 0.058\n",
      "[27,  1013] loss: 0.052\n",
      "[28,  1013] loss: 0.050\n",
      "[29,  1013] loss: 0.049\n",
      "[30,  1013] loss: 0.047\n",
      "[31,  1013] loss: 0.045\n",
      "[32,  1013] loss: 0.041\n",
      "[33,  1013] loss: 0.045\n",
      "[34,  1013] loss: 0.044\n",
      "[35,  1013] loss: 0.033\n",
      "[36,  1013] loss: 0.039\n",
      "[37,  1013] loss: 0.042\n",
      "[38,  1013] loss: 0.037\n",
      "[39,  1013] loss: 0.039\n",
      "[40,  1013] loss: 0.032\n",
      "[41,  1013] loss: 0.033\n",
      "[42,  1013] loss: 0.038\n",
      "[43,  1013] loss: 0.036\n",
      "[44,  1013] loss: 0.026\n",
      "[45,  1013] loss: 0.031\n",
      "[46,  1013] loss: 0.031\n",
      "[47,  1013] loss: 0.031\n",
      "[48,  1013] loss: 0.032\n",
      "[49,  1013] loss: 0.030\n",
      "[50,  1013] loss: 0.022\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(60):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000))\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X\n",
    "test_X_tensor = np.expand_dims(test_X, 1)\n",
    "test_X_tensor = torch.from_numpy(test_X_tensor).float().cuda()\n",
    "model.eval()\n",
    "prediction = model(test_X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 3 ... 3 6 6]\n",
      "[2 2 2 ... 4 4 4]\n",
      "0.43253437157805086\n"
     ]
    }
   ],
   "source": [
    "prob = torch.nn.functional.softmax(prediction, dim=1)\n",
    "final = torch.argmax(prob, dim=1).cpu().numpy()\n",
    "print(final)\n",
    "print(test_Y)\n",
    "print(np.sum(np.equal(final, test_Y)) / len(test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 0 7 0 5 1 0 0 2 2 1 4 1 7 2 0 0 7 4 0 5 0 0 1 0 2 3 2 0 0]\n",
      "[1 2 2 0 7 0 5 1 0 0 2 2 1 4 1 7 2 0 0 7 4 0 5 0 0 1 0 2 3 2 0 0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "idx, (data, label) = next(enumerate(loader))\n",
    "data = model(data.cuda())\n",
    "prob = torch.nn.functional.softmax(data, dim=1)\n",
    "final = torch.argmax(prob, dim=1).cpu().numpy()\n",
    "label = label.numpy()\n",
    "print(final)\n",
    "print(label)\n",
    "print(np.equal(final, label).sum() / len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
